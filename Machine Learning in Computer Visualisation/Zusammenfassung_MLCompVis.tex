\documentclass[11pt]{article}

\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage[a4paper,margin=1cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{isodate}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage{tabularx}
\usepackage{ltablex} % Longtables with tabularx
\usepackage[x11names]{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{lscape}
\usepackage{geometry}
\usepackage{multicol}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{mdframed}
\usepackage{scalerel}
\usepackage{stackengine}
\usepackage{mathtools}
\usepackage{pdfpages}

% Code highlighting
\usepackage{minted}
\usepackage{pythonhighlight}
\surroundwithmdframed{minted}

% Be able to caption equations and float them in place
\usepackage{float}

\usepackage{csquotes}
\usepackage{hyperref}

\newmdtheoremenv{theorem}{Theorem}
\geometry{a4paper, margin=2.4cm}

\newcommand\equalhat{\mathrel{\stackon[1.5pt]{=}{\stretchto{\scalerel*[\widthof{=}]{\wedge}{\rule{1ex}{3ex}}}{0.5ex}}}}
\newcommand\defeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny def}}}{=}}}
\newcolumntype{C}{>{\centering\arraybackslash}X}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}

\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

\graphicspath{{./img/}}

\begin{document}
	
\title{Machine Learning in Computer Vision FS20}
\author{Pascal Baumann\\pascal.baumann@stud.hslu.ch}
\maketitle



For errors or improvement raise an issue or make a pull request on the \href{https://github.com/KilnOfTheSecondFlame/mse_summaries}{github repository}.

\tableofcontents
\newpage


\section{Image Handling in Python}

\begin{minted}[tabsize=2]{python}
plt.imshow(np.hstack((im_float, im_float)), cmap="gray", vmin=0, vmax=1);
\end{minted}

\begin{center}
	\includegraphics[width=0.7\linewidth]{img/hstack_image}
\end{center}

\subsection{Fading an Image}
\begin{minted}[tabsize=2]{python}
im = skimage.io.imread("data/snoopy.png")
im = im/255 # tip: use floating point values

ims = []

im_temp = np.fliplr(im)
ims.append(im_temp)
for i in range(1,5):
	im_temp = im_temp + (0.4)**i
	ims.append(im_temp)

plt.imshow(np.hstack(ims),vmin=0, vmax=1, cmap="gray")
\end{minted}

\begin{center}
	\includegraphics[width=0.7\linewidth]{img/snoopy_fade}
\end{center}

\subsubsection{IPyWidgets}
\begin{minted}[tabsize=2]{python}
@interact(thresh=widgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.2))
def threshold(thresh):
	im_thresh = []
	for line in im:
		im_thresh.append([pixel if pixel > np.min(line) 
			+ thresh else float(0) for pixel in line])
	plt.imshow(im_thresh, cmap="gray", vmin=0, vmax=1)
	plt.show()
\end{minted}

\begin{center}
	\includegraphics[width=0.6\linewidth]{img/ipywidgets_example}
\end{center}

\section{Local Filtering and Edge Detection}
\subsection{Filtering}
The naive approach of local filtering is taking just a moving average of the pixels in the neighbourhood.

\subsection{Edge Detection}
Although intuitive for humans to detect, edge detection was a hard problem in image processing. And edge is defined by a rapid change in the intensity, which can be exploited by calculating the derivative.

\begin{center}
	\includegraphics[width=0.6\linewidth]{img/1D_edge_derivative}
\end{center}

\noindent
In two dimensions the derivative corresponds to the gradient $\nabla f = \left[\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\right]$, which points from the edge towards the increase in intensity or the lighter side.

\begin{align}
\shortintertext{Gradient}
\nabla f &= \left[ \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \right]
\shortintertext{Gradient Direction}
\theta &= \tan^{-1} \left( \frac{\partial f}{\partial x} / \frac{\partial f}{\partial y} \right)
\shortintertext{Gradient Magnitude (strength of the edge)}
\norm{\nabla f} &= \sqrt{\left(\frac{\partial f}{\partial x}\right)^2 + \left(\frac{\partial f}{\partial y} \right)^2 }
\end{align}

But not all important edges have strong gradients, nor are all strong gradients important edges.

\subsubsection{Computing the Gradient on an Image}

Approximate Gradient in direction of $ \frac{\partial f}{\partial x} $: Convolution with kernel \begin{tabular}{|c|c|}
	\hline
	-1 & 1\\
	\hline
\end{tabular}

\noindent
Approximate Gradient in direction of $ \frac{\partial f}{\partial y} $: Convolution with kernel \begin{tabular}{|c|}
	\hline
	-1 \\
	\hline
	1\\
	\hline
\end{tabular}

The drawback of the gradient is, that it is very sensitive to noise:
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{img/noise_gradient}
	\caption{Gradient of a 1D function, where it is clear how it amplifies noise and may conceal a weak signal}
	\label{fig:noisegradient}
\end{figure}

\noindent
The solution to this is, to first smooth the function and then apply the gradient.

The larger the value of $\sigma$ the more smoothing is applied and different kind of features can be identified.
\begin{itemize}[leftmargin=*, labelindent=3.5cm, labelsep=0.5cm]
	\item[\textbf{large value of $\sigma$}] larger scale or stronger edges detected
	\item[\textbf{smaller value of $\sigma$}] finer details detected
\end{itemize}

\noindent
\begin{minipage}{0.6\textwidth}
	In practice a convolution with a derivative of Gaussian filter is calculated to compute the gradients.
	
	This is equivalent to smoothing with a Gaussian and then taking the derivative.
\end{minipage}
\begin{minipage}{0.4\textwidth}
	\begin{center}
		\includegraphics[width=0.6\linewidth]{img/derivative_gaussian_filter}
	\end{center}
\end{minipage}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth]{img/derivative_gaussian_filter2}
	\caption{Derivative of Gaussian Filters}
	\label{fig:derivativegaussianfilter2}
\end{figure}

\begin{itemize}
	\item A Gaussian smoothing filter removes high-frequency components
	\item Values of a Gaussian smoothing filter sum to one
	\item Derivative filters contain some negative value and values sum to zero
	\item Derivative filters yield large responses at points with high contrast
\end{itemize}

\subsection{Canny Edge Detection}
Same base approach but enhanced with edge thinning and hysteresis thresholding.
\begin{enumerate}
	\item Approximate gradients along axes by derivative of Gaussian filters
	\item Compute gradient magnitude
	\item Make edge one pixel wide, thinning through \textbf{non-maxima suppression} along perpendicular direction to the edge
	\item Only keep strong edges through hysteresis thresholding 
\end{enumerate}

\subsection{Hysteresis Thresholding}
This stage decides which are all edges are really edges and which are not. For this, we need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded. Those who lie between these two thresholds are classified edges or non-edges based on their connectivity. If they are connected to "sure-edge" pixels, they are considered to be part of edges. Otherwise, they are also discarded.
	
\begin{figure}[H]
	\centering
	\includegraphics[keepaspectratio,width=0.6\linewidth]{hysteresis_thresholding}
	\caption{Hysteresis thresholding with A) sure edge, B) non-edge and C) a non-edge connected to a sure edge}
\end{figure}

\section{Model Fitting and Line and Circle Detection}
Edge detection is usually not enough as there are usually more than one line in an image and many edges that do not belong to a line. There might be noise in the edges belonging to a line which brings them out of alignment. Lines might also not be complete.

\subsection{Model Fitting}
Model fitting is an algorithm finds or fits a high-level explanation or model that explain the observation well. In this case the edges are the observations and the model are one or more line.

\subsection{Voting Algorithms}
Voting algorithms are a general technique for decision methods.

\begin{enumerate}
	\item Every feature casts votes for all models that are compatible with it
	\item Choose models that accumulate a lot of votes
\end{enumerate}

Clutter and noise will cast a lot of votes, but are inconsistent. Instead, features belonging to a model will concentrate a lot of votes for that model.

\subsection{Hough Transform}
\begin{enumerate}
	\item Every \textbf{edge point} casts votes for \textbf{all lines that are compatible} with it
	\item Choose \textbf{lines} that accumulated a lot of votes
\end{enumerate}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth,keepaspectratio]{img/line_representation_hough}
	\caption{Line representation in Hough space}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{img/points_representation_hough}
	\caption{Points on a line in normal space almost intersect in Hough space}
	\label{fig:pointsrepresentationhough}
\end{figure}

\noindent
The problem with this approach is that
\begin{enumerate}[label=\alph*.]
	\item the parameter space $(m,b)$ is \textbf{not bounded}
	\item \textbf{vertical lines} can not be represented
\end{enumerate}

\subsection{Representation of Lines in Polar Coordinates}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{img/line_representation_polar}
	\caption{Line representation with polar parameters}
	\label{fig:linerepresentationpolar}
\end{figure}

This approach solves both the problem of unboundedness and representation. The parameter $\theta$ is bounded by $[0,2\pi]$ and $d$ by $[0,\text{imagewidth}]$.

For every point in normal space there will be a Sinusoid the polar Hough space.

\subsection{Hough Transformation Algorithm}
The algorithm transforms each edge point in the image to the Hough space, where an Accumulator array gets filled with votes. The bin size of the accumulator is an important hyperparameter, if the size is too small, there will be many weak peak due to noise, if too large accuracy of locating a line drops and many votes from clutter might end up in the same bin. A solution is to keep the bin size small but also count votes from neighbours.

% TODO Hough circles

\subsubsection{Voting Algorithm for Finding Lines}
\begin{enumerate}
	\item Every edge point casts votes for all circles that are compatible with it
	\item We choose circles that accumulated a lot of votes
\end{enumerate}

\begin{theorem}
	Parametrisation of a circle
	\begin{equation*}
		(x_i - a)^2 + (y_i - b)^2 = r^2
	\end{equation*}
	With centre $(a,b)$ and radius $r$
\end{theorem}

\begin{center}
	\includegraphics[width=0.7\linewidth]{img/hough_circle_accumulator}
\end{center}

\subsection{Hough Space for Circles With Unknown Radius}

\begin{center}
	\includegraphics[width=0.7\linewidth]{img/hough_circle_accumulator_point}
\end{center}




\end{document}
